{"cells":[{"cell_type":"markdown","source":["I'll Be training my LSTM Model on 2 themes for now : Animal and Buildings \n","\n","-the entered Textsshould be only Animal and Buildings Textes from our actual base \"wikipedia\"\n","\n","```\n","with open(filename, encoding = \"ISO-8859-1\") as f:\n","```\n","\n","- LSTM is a RNN architecture which doesn't understand Strs like \"animal\" so you need to encode it with \n","\n","```\n","Word2vec \n","```\n","each word will be represented by a numerical vector.\n","\n","-Callbacks will help you gain time while training the model\n"],"metadata":{"id":"KCOsQRxWFYu2"}},{"cell_type":"markdown","source":["Let's Begin"],"metadata":{"id":"h3lpWqOGGaWA"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"tAb77yZ9fzMG","executionInfo":{"status":"ok","timestamp":1658743883055,"user_tz":-120,"elapsed":789,"user":{"displayName":"Maha Mallek","userId":"10352951650678180202"}}},"outputs":[],"source":["import pickle"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e7af5418-bc6e-4ecd-8d48-6a1c2a83a7c3","id":"7_gQEv8jB5nN","executionInfo":{"status":"ok","timestamp":1658743900686,"user_tz":-120,"elapsed":12731,"user":{"displayName":"Maha Mallek","userId":"10352951650678180202"}}},"source":["!pip3 install --upgrade gensim --user"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n","Collecting gensim\n","  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n","\u001b[K     |████████████████████████████████| 24.1 MB 1.5 MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n","Installing collected packages: gensim\n","Successfully installed gensim-4.2.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"c206d424-611d-4bb7-b4ef-a207e6d34b86","id":"3WWkevwIB5nO","executionInfo":{"status":"ok","timestamp":1658743907163,"user_tz":-120,"elapsed":4178,"user":{"displayName":"Maha Mallek","userId":"10352951650678180202"}}},"source":["\n","import tensorflow as tf\n","tf.test.gpu_device_name() #TensorFlow is an end-to-end open source platform for machine learning"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["''"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["The textes should be cleaned and cuted into sequences "],"metadata":{"id":"nVj59U6SGf2_"}},{"cell_type":"code","source":["import nltk #Natural Language Toolkit est une bibliothèque logicielle en Python permettant un traitement automatique des langues\n","from nltk.corpus import stopwords \n","\n","nltk.download('punkt')\n","nltk.download(\"stopwords\") \n","stop_words = set(stopwords.words('english')) \n","print(stop_words)\n","from keras.preprocessing.text import Tokenizer\n","#La bibliothèque Keras permet d'interagir avec les algorithmes de réseaux de neurones profonds et d'apprentissage automatique, notamment Tensorflow, Theano, Microsoft Cognitive Toolkit4 ou PlaidML.\n","#Conçue pour permettre une expérimentation rapide avec les réseaux de neurones profonds\n","\n","from nltk.tokenize import word_tokenize,sent_tokenize\n","import numpy as np\n","import re\n","#from keras.utils import to_categorical\n","import string\n","import re\n","\n","cleaned =\"\"\n","sentences=[]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n_8NZlgqecqC","outputId":"822eaa5a-c8ee-45cc-9c1f-61a558b59761","executionInfo":{"status":"ok","timestamp":1658743911898,"user_tz":-120,"elapsed":3149,"user":{"displayName":"Maha Mallek","userId":"10352951650678180202"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["{'it', 'under', 'did', 'has', 'into', 'more', \"hasn't\", 'were', 'an', 'couldn', 'll', 'in', 'but', 'so', \"mightn't\", 'you', \"you've\", 'd', 'before', 'hasn', 'had', 'doesn', 'for', 'all', 's', 're', 'yourself', \"she's\", 'needn', 'their', 'about', 'doing', \"won't\", \"shan't\", 'hers', 'my', 'those', \"don't\", 'she', 'on', 'each', \"needn't\", 'don', \"weren't\", 'both', 'where', 'few', 'whom', 'who', 'isn', 'we', 'just', 'been', 'do', 'its', 'at', 'off', 'how', 'no', 'shouldn', \"wouldn't\", 'some', \"didn't\", 'below', 'while', 'me', 'ma', \"should've\", 've', \"haven't\", 'ours', \"hadn't\", 'out', 'nor', 'other', 't', 'there', 'myself', 'them', \"you're\", 'they', 'wouldn', 'that', 'shan', 'during', 'o', 'the', 'than', 'y', 'your', 'from', 'again', 'herself', \"you'll\", 'then', 'yourselves', 'down', \"aren't\", 'mustn', \"that'll\", 'ain', 'mightn', \"wasn't\", \"it's\", 'or', 'of', 'i', 'which', 'this', 'against', 'up', 'himself', 'these', 'ourselves', 'yours', 'by', 'him', 'itself', 'as', 'aren', 'until', 'over', 'haven', \"shouldn't\", 'm', 'not', \"mustn't\", 'our', 'any', 'after', \"doesn't\", 'is', 'most', 'through', 'because', 'are', 'was', 'if', 'themselves', 'only', 'his', 'further', 'can', 'with', 'being', 'should', 'theirs', 'weren', 'wasn', 'will', 'such', 'what', \"isn't\", \"couldn't\", 'when', 'didn', 'between', 'here', 'have', 'same', 'her', 'above', 'too', \"you'd\", 'he', 'having', 'own', 'a', 'now', 'won', 'very', 'am', 'does', 'and', 'hadn', 'to', 'be', 'why', 'once'}\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","source":["for i in range(10,16):\n","      filename = \"text (\"+str(i)+\").txt\"\n","      with open(filename, encoding = \"ISO-8859-1\") as f:\n","         cleaned = cleaned+\" \"+f.read().lower()"],"metadata":{"id":"qoQOBa2GegF4","colab":{"base_uri":"https://localhost:8080/","height":217},"executionInfo":{"status":"error","timestamp":1658744219544,"user_tz":-120,"elapsed":294,"user":{"displayName":"Maha Mallek","userId":"10352951650678180202"}},"outputId":"71483ef3-7cbc-4ce2-b056-46f076358d07"},"execution_count":10,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-b01898de62aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m       \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"text (\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\").txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ISO-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m          \u001b[0mcleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaned\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'text (10).txt'"]}]},{"cell_type":"markdown","source":["# Nouvelle section"],"metadata":{"id":"PrHOWaOS2OG5"}},{"cell_type":"code","source":["cleaned = cleaned.replace(\"\\n\", \" \")\n","punctuation=\"\\\"#$%&()*+,-/:;<=>@[\\]^_`{|}~\"\n","for p in cleaned :\n","    cleaned=cleaned.replace(p,re.sub('[\\d_]+','',p)) #remove numbers and replace \n","    encoded_string= p.encode(\"ascii\", \"ignore\")\n","    cleaned = cleaned.replace(p,encoded_string.decode())\n","    if p in punctuation :\n","     cleaned=cleaned.replace(p, '')\n","sentences=[]\n","temp = []\n","for i in sent_tokenize(cleaned):\n","    \n","    for j in word_tokenize(i) :\n","      if (j not in string.punctuation):\n","       temp.append(j.lower())\n","    sentences.append(temp)\n"],"metadata":{"id":"fCITjZhLelsW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#print(sentences)\n","\n","train_len = 5 \n","text_sequences = []\n","for sent in sentences:\n"," for i in range(train_len,len(sent)+1):\n","    seq = sent[i-train_len:i]\n","    text_sequences.append(seq)"],"metadata":{"id":"ePJCeabXe84M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### N.B: \n","I have tranked the \"text sequences\" into 4 sequences because of Colab low capacity"],"metadata":{"id":"L9QhhPG6B7tN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pafL7Li0jyXW"},"outputs":[],"source":["with open(\"sequences1.txt\", \"rb\") as fp:   # Unpickling\n","    text_sequences1=pickle.load(fp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FbbBTNi22m7V"},"outputs":[],"source":["with open(\"sequences2.txt\", \"rb\") as fp:   # Unpickling\n","    text_sequences2=pickle.load(fp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pDCLeC0q3oQN"},"outputs":[],"source":["with open(\"sequences3.txt\", \"rb\") as fp:   # Unpickling\n","    text_sequences3=pickle.load(fp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ir-rM3Ba3qRD"},"outputs":[],"source":["with open(\"sequences4.txt\", \"rb\") as fp:   # Unpickling\n","    text_sequences4=pickle.load(fp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Ar9PCEe3kYD"},"outputs":[],"source":["text_sequences=text_sequences1+text_sequences4+text_sequences3+text_sequences2"]},{"cell_type":"markdown","source":["Added not necessary"],"metadata":{"id":"ojj_LFcyC8Dm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OCj3qfU73892"},"outputs":[],"source":["with open(\"sequences.txt\", \"wb\") as fp:   #Pickling  #change 1 2 3 4\n","   pickle.dump(text_sequences, fp)\n","print(\"text_sequences \")"]},{"cell_type":"markdown","source":["### **Word2Vec**"],"metadata":{"id":"ewCQoxUNC1Ht"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2bD1O29P7qjv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3f94e01c-3f26-48d7-9d92-2164994ac361"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training word2vec model\n","Result embedding shape: (6829, 100)\n"]}],"source":["import gensim\n","print('\\nTraining word2vec model')\n","word_model = gensim.models.Word2Vec(text_sequences, size=100, min_count=1, window=5, iter=4)\n","pretrained_weights = word_model.wv.vectors\n","vocab_size, emdedding_size = pretrained_weights.shape\n","print('Result embedding shape:', pretrained_weights.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rzNxMJjl7wUq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6c0e6052-e69a-4584-96df-fecf74c16b53"},"outputs":[{"output_type":"stream","name":"stdout","text":["Result embedding shape: (6829, 100)\n"]}],"source":["from gensim.models import KeyedVectors\n","word_model.init_sims(replace=True)\n","pretrained_weights = word_model.wv.vectors\n","\n","pretrained_weights = word_model.wv.vectors\n","vocab_size, emdedding_size = pretrained_weights.shape\n","print('Result embedding shape:', pretrained_weights.shape)\n","\n","word_model.save(\"word2vecm1234.model\") #if you want to save Word2Vec"]},{"cell_type":"markdown","source":["Loading Word2Vec Model that you just saved"],"metadata":{"id":"DHD3F7-yDD2t"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"C5rn1XZ97zMD"},"outputs":[],"source":["from gensim.models import KeyedVectors\n","word_model = gensim.models.KeyedVectors.load(\"word2vecm1234.model\",mmap='r')\n"]},{"cell_type":"code","source":["pretrained_weights = word_model.wv.vectors\n","vocab_size, emdedding_size = pretrained_weights.shape\n","print('Result embedding shape:', pretrained_weights.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vrz4HfpWeKYj","outputId":"d4780575-deac-4e43-f2c6-61d9881e735b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Result embedding shape: (6829, 100)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PU8-Q8VJ9GJj"},"outputs":[],"source":["def word2idx(word):\n","  return word_model.wv.vocab[word].index\n","def idx2word(idx):\n","  return word_model.wv.index2word[idx]"]},{"cell_type":"markdown","metadata":{"id":"sOxQB1FF8w6B"},"source":["callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3) #method that helps you gain time when training the model\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"VGCplIUE80gm","executionInfo":{"status":"ok","timestamp":1658743946644,"user_tz":-120,"elapsed":354,"user":{"displayName":"Maha Mallek","userId":"10352951650678180202"}}},"outputs":[],"source":["from tensorflow import keras"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"a1kCucpv9ILN","colab":{"base_uri":"https://localhost:8080/","height":269},"outputId":"24a9c905-825c-466d-8edb-fd4b62f53a13","executionInfo":{"status":"error","timestamp":1658743949940,"user_tz":-120,"elapsed":386,"user":{"displayName":"Maha Mallek","userId":"10352951650678180202"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Preparing the data for LSTM...\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-d53db79ddf61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nPreparing the data for LSTM...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msin\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'text_sequences' is not defined"]}],"source":["\"\"\"# LSTM Model\"\"\"\n","\n","import numpy as np\n","\n","print('\\nPreparing the data for LSTM...')\n","train_x = np.zeros([len(text_sequences), 5], dtype=np.int32)\n","train_y = np.zeros([len(text_sequences)], dtype=np.int32)\n","for i, sin in enumerate(text_sequences):\n","  for t, word in enumerate(sin[:-1]): #54 ['two', 'positions', 'are', 'incompatiblewhile', 'others']\n","    train_x[i][t] = word2idx(word)  \n","  train_y[i] = word2idx(sin[-1]) \n","print('train_x shape:', train_x.shape)\n","print('train_y shape:', train_y.shape)\n","print(train_y)\n","\n"]},{"cell_type":"code","source":["vocab_size"],"metadata":{"id":"p4R5a4V8Fnt3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"907378ea-aac5-4c41-cca1-ef00f642f131"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6829"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["emdedding_size"],"metadata":{"id":"YLp7P9r0Frdz","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2849e8b0-4939-4d56-ba23-34421a0fea22"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["100"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["import tensorflow as tf\n"],"metadata":{"id":"VGEeBPUSF0F0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.layers import Dropout\n","from keras.layers import Embedding\n","from keras.layers import Bidirectional\n","\n","model = Sequential()\n","model.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, weights=[pretrained_weights]))\n","model.add(LSTM(256, return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(256))\n","model.add(Dropout(0.2))\n","model.add(Dense(vocab_size, activation='softmax'))\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"],"metadata":{"id":"6D4FLmnRqvUt","colab":{"base_uri":"https://localhost:8080/","height":252},"executionInfo":{"status":"error","timestamp":1658743964071,"user_tz":-120,"elapsed":250,"user":{"displayName":"Maha Mallek","userId":"10352951650678180202"}},"outputId":"16b37b9c-1f31-4a46-f9ad-74e23f1c7db5"},"execution_count":7,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-d56b6067f7be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memdedding_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpretrained_weights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'vocab_size' is not defined"]}]},{"cell_type":"code","source":["EPOCHS = 10\n","class myCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs={}):\n","    '''\n","    Halts the training after reaching 60 percent accuracy\n","\n","    Args:\n","      epoch (integer) - index of epoch (required but unused in the function definition below)\n","      logs (dict) - metric results from the training epoch\n","    '''\n","\n","    # Check accuracy\n","    if((logs.get('loss') < 0.4) & (logs.get('accuracy')>=0.99)):\n","\n","      # Stop if threshold is met\n","      print(\"\\nLoss is lower than 0.4 so cancelling training!\")\n","      self.model.stop_training = True\n","\n","# Instantiate class\n","callbacks = myCallback()"],"metadata":{"id":"EpjaOHlCqyew"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","xtrain, xtest, ytrain, ytest = train_test_split(train_x, train_y, train_size=0.8)"],"metadata":{"id":"ePpxkUk460yJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","xtrain, xtest, ytrain, ytest = train_test_split(train_x, train_y, train_size=0.8)\n","# Model weights are saved at the end of every epoch, if it's the best seen\n","# so far.\n","model.fit(train_x, train_y,\n","          batch_size=128,\n","          epochs=EPOCHS,\n","          callbacks=[callbacks]\n","          \n","        )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":414},"id":"c1OLH75Jq1rI","outputId":"6304f639-c4e0-4afe-94b8-d2d71393e883"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","   516/121403 [..............................] - ETA: 3:14:08 - loss: 6.6941 - accuracy: 0.0802"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-93-f8fc97ddf603>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["model.evaluate(xtest,ytest) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ioyskT2gq3bs","outputId":"8b84e3a6-5502-4824-c115-1eb95ded2c85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["121403/121403 [==============================] - 1112s 9ms/step - loss: 0.0220 - accuracy: 0.9892\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.021954642608761787, 0.9891778230667114]"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["\n","\n","model.save('model_IA_Buildings.h5') #why bc : I've trained my LSTM model on 2 topics \n","\n","#from tensorflow import keras\n","#model = keras.models.load_model('model.h5')"],"metadata":{"id":"lTWkQqvSq4Ha"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow import keras\n","model = keras.models.load_model('model_IA_Buildings.h5')"],"metadata":{"id":"cqiCzPTlVsEg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.evaluate(xtest,ytest)\n","\n","model.save('model.h5')\n","\n","#from tensorflow import keras\n","#model = keras.models.load_model('model.h5')"],"metadata":{"id":"V_RuPAba94TG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"9TBQt73Onz4r"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"machine_shape":"hm","name":"LSTM_Model (1).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}